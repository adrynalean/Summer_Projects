{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOArvIsDAELmICiQ7jhtE5e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrynalean/Summer_Projects/blob/MNIST_machine/MNIST_Recognition_machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up imports"
      ],
      "metadata": {
        "id": "09yCEjD5eGIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19EoU7esYg4K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set manual seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "id": "K1rAYcOskJzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining transformation\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n"
      ],
      "metadata": {
        "id": "f4kifpkWe-gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data sets\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "# # Verify Data\n",
        "\n",
        "# examples = enumerate(train_loader)\n",
        "# batch_idx, (example_data, example_targets) = next(examples)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# for i in range(6):\n",
        "#     plt.subplot(2, 3, i+1)\n",
        "#     plt.tight_layout()\n",
        "#     plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "#     plt.title(f\"Label: {example_targets[i]}\")\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "# plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lIuLzcV0eFru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the Model\n",
        "class MNIST_model0(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MNIST_model0, self).__init__()\n",
        "    self.layer_1 = nn.Linear(28*28, 512)\n",
        "    self.layer_2 = nn.Linear(512, 256)\n",
        "    self.layer_3 = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28*28)  # This flattens the image into one huge array\n",
        "    x = torch.relu(self.layer_1(x))\n",
        "    x = torch.relu(self.layer_2(x))\n",
        "    x = self.layer_3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "model1 = MNIST_model0()\n",
        "model1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsh9zoeghlxy",
        "outputId": "cd3c3396-80e6-4537-8cb2-bff9a9388d03",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNIST_model0(\n",
              "  (layer_1): Linear(in_features=784, out_features=512, bias=True)\n",
              "  (layer_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (layer_3): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device agnostic Code\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model1.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d51YyEG9kmwz",
        "outputId": "297ce4df-a3d9-4b4f-8742-f5c1dfe41d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNIST_model0(\n",
              "  (layer_1): Linear(in_features=784, out_features=512, bias=True)\n",
              "  (layer_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (layer_3): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a loss function and a optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model1.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "ZfiYaQN3jKz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's train the model!\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  model1.train()\n",
        "  train_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "     # 1. Zero Grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 2. Forward Pass\n",
        "    output = model1(data)\n",
        "\n",
        "    # 3. Calculate the loss\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # 4. Backpropogation\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step ( updating the weights )\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    total += target.size(0)\n",
        "    correct += (predicted == target).sum().item()\n",
        "\n",
        "  train_acc = 100 * correct / total\n",
        "\n",
        "\n",
        "  ### Testing\n",
        "  model1.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "\n",
        "      output = model1(data)\n",
        "      loss = criterion(output, target)\n",
        "      test_loss += loss.item()\n",
        "      _, predicted = torch.max(output.data, 1)\n",
        "      total += target.size(0)\n",
        "      correct += (predicted == target).sum().item()\n",
        "\n",
        "    test_acc = 100 * correct / total"
      ],
      "metadata": {
        "id": "_kF69NVJjgAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's print it out\n",
        "\n",
        "print(f'Epoch {epoch+1}/{epochs}, '\n",
        "        f'Train Loss: {train_loss/len(train_loader):.4f}, '\n",
        "        f'Train Acc: {train_acc:.2f}%, '\n",
        "        f'Test Loss: {test_loss/len(test_loader):.4f}, '\n",
        "        f'Test Acc: {test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrpmQhXamZRy",
        "outputId": "0c8dafbf-c66a-4126-bf5a-cd2a2dec9726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5, Train Loss: 0.0370, Train Acc: 98.81%, Test Loss: 0.0732, Test Acc: 97.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Visualize Visualize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Load the test dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Get some random test images\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % labels[j].item() for j in range(4)))\n",
        "\n",
        "# Move the images to the appropriate device\n",
        "images = images.to(device)\n",
        "\n",
        "# Predict the classes\n",
        "model1.eval()  # Set the model to evaluation mode\n",
        "outputs = model1(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % predicted[j].item() for j in range(4)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "fUohPkp5mdNh",
        "outputId": "4fe3e85f-e2f6-40ed-a5af-685c01e276a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GroundTruth:      2     7     0     5\n",
            "Predicted:      2     7     0     5\n"
          ]
        }
      ]
    }
  ]
}