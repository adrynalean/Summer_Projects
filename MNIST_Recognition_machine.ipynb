{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMG3Wy4bmvS/l7/i0BelE5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrynalean/Summer_Projects/blob/MNIST_machine/MNIST_Recognition_machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up imports"
      ],
      "metadata": {
        "id": "09yCEjD5eGIm"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "19EoU7esYg4K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set manual seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "id": "K1rAYcOskJzq"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining transformation\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n"
      ],
      "metadata": {
        "id": "f4kifpkWe-gn"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data sets\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "# # Verify Data\n",
        "\n",
        "# examples = enumerate(train_loader)\n",
        "# batch_idx, (example_data, example_targets) = next(examples)\n",
        "\n",
        "# fig = plt.figure()\n",
        "# for i in range(6):\n",
        "#     plt.subplot(2, 3, i+1)\n",
        "#     plt.tight_layout()\n",
        "#     plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "#     plt.title(f\"Label: {example_targets[i]}\")\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "# plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lIuLzcV0eFru"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the Model\n",
        "class MNIST_model0(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MNIST_model0, self).__init__()\n",
        "    self.layer_1 = nn.Linear(28*28, 512)\n",
        "    self.layer_2 = nn.Linear(512, 256)\n",
        "    self.layer_3 = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28*28)  # This flattens the image into one huge array\n",
        "    x = torch.relu(self.layer_1(x))\n",
        "    x = torch.relu(self.layer_2(x))\n",
        "    x = self.layer_3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "model1 = MNIST_model0()\n",
        "model1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsh9zoeghlxy",
        "outputId": "99bd6097-2c18-44f4-eee0-b7bc33a3d432",
        "collapsed": true
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNIST_model0(\n",
              "  (layer_1): Linear(in_features=784, out_features=512, bias=True)\n",
              "  (layer_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (layer_3): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device agnostic Code\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model1.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d51YyEG9kmwz",
        "outputId": "0f4c62d4-0bdd-4a6f-89fd-9e56adbccbfe"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNIST_model0(\n",
              "  (layer_1): Linear(in_features=784, out_features=512, bias=True)\n",
              "  (layer_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (layer_3): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a loss function and a optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model1.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "ZfiYaQN3jKz2"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's train the model!\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  model1.train()\n",
        "  train_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "     # 1. Zero Grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 2. Forward Pass\n",
        "    output = model1(data)\n",
        "\n",
        "    # 3. Calculate the loss\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # 4. Backpropogation\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step ( updating the weights )\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    total += target.size(0)\n",
        "    correct += (predicted == target).sum().item()\n",
        "\n",
        "  train_acc = 100 * correct / total\n",
        "\n",
        "\n",
        "  ### Testing\n",
        "  model1.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "\n",
        "      output = model1(data)\n",
        "      loss = criterion(output, target)\n",
        "      test_loss += loss.item()\n",
        "      _, predicted = torch.max(output.data, 1)\n",
        "      total += target.size(0)\n",
        "      correct += (predicted == target).sum().item()\n",
        "\n",
        "    test_acc = 100 * correct / total"
      ],
      "metadata": {
        "id": "_kF69NVJjgAi"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's print it out\n",
        "\n",
        "print(f'Epoch {epoch+1}/{epochs}, '\n",
        "        f'Train Loss: {train_loss/len(train_loader):.4f}, '\n",
        "        f'Train Acc: {train_acc:.2f}%, '\n",
        "        f'Test Loss: {test_loss/len(test_loader):.4f}, '\n",
        "        f'Test Acc: {test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrpmQhXamZRy",
        "outputId": "755e972e-ebc6-4c54-ba78-3f35f10a92e9"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5, Train Loss: 0.0370, Train Acc: 98.81%, Test Loss: 0.0732, Test Acc: 97.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Visualize Visualize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Load the test dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Get some random test images\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % labels[j].item() for j in range(4)))\n",
        "\n",
        "# Move the images to the appropriate device\n",
        "images = images.to(device)\n",
        "\n",
        "# Predict the classes\n",
        "model1.eval()  # Set the model to evaluation mode\n",
        "outputs = model1(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % predicted[j].item() for j in range(4)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "fUohPkp5mdNh",
        "outputId": "1a703f60-eb3a-440b-b3ec-307b1971a8eb"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GroundTruth:      1     3     4     4\n",
            "Predicted:      1     3     4     4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's save our model\n",
        "\n",
        "torch.save(model1.state_dict(), 'mnist_model.pth')\n",
        "print(\"Model saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy2ZPkhKshdt",
        "outputId": "aa62b45f-c30d-4941-f3c0-2d7ec79cdba3"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ]
    }
  ]
}